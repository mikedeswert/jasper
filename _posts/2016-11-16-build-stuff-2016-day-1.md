---
layout: post
cover: 'assets/images/2016-11-16-build-stuff-2016-day-1/cover.png'
title: Build Stuff 2016 - Day 1
date:   2016-11-16 21:56
tags: buildstuff2016
subclass: 'post tag-content'
categories: 'buildstuff2016'
navigation: true
disqus: true
logo: 'assets/images/ghost.png'
---

Today Build Stuff 2016 officially kicked off. This year is the conference's fifth anniversary and the theme is centered around "Old New Things" i.e. finding a new purpose for old tech, but perhaps also a play on how the software industry seems to rediscover the same ideas every few years.

Here is a list of the talks I attended today:

- [The Long Sad History of Microservices](#the-long-sad-history-of-microservices)
- [New Adventures in Responsive Web Design](#new-adventures-in-responsive-web-design)

### The Long Sad History of Microservices 
> Greg Young ([@gregyoung](https://twitter.com/gregyoung))

Greg Young got the ball rolling; giving the first presentation of the day. He talked about micro services and how they too are an "old new thing".  
Microservices are not a new concept. The idea of splitting things up in isaloted components has actually existed for five decades.  
He then used Service Oriented Architecture, Corba and DCOM as examples of earlier iterations of the same principle. He even went as far back as the 1950s; 
where we implemented distributed systems with people instead of computers. When you watch movies from this time period, it's not uncommon to see a room people sitting behind typewriters, 
with "in" and "out" boxes on their desk and a mailman going around distributing and collecting messages.

Sound familiar?

I found this be an interesting comparison as it demonstrates how modern technologies and architectures always seem to be based on ideas that have existed for ages.

During the presentation it became clear that Greg is not really a fan of microservices, but considering the title of the talk that did not really come as a surprise. 

Now whether you like or hate microservices, I find Greg to be a great speaker and there were some great take-aways that I will gladly share with you.

***In most systems you do not want to distribute up front***  
Nine times out of ten, distributing a system is simply overkill. It adds a lot of overhead and complexity and can greatly increase the development cost. For many business apps, microservices are not a good fit.  
If during the project it looks like your application will actually benefit from being split up into microservices, only then do you want to start implementing it.

***Distribute for availability, not scalability***  
If your application does not need to be available 24 hours a day, 365 days a year; don't even consider using microservices.

I personally think that in order to even consider microservices (or any distributed system for that matter) you also need a team that's mature enough or you're setting yourself up for failure.

Greg mentioned a nice quote from Simon Brown that I believe supports this thought:

> *If you can't build a structured monolith*  
> *what makes you think microservices is the answer?*  

***Monolith and Microservices are not the only solutions***  
It's not necessarily one or the other. There is a lot of middle ground when splitting up an application into separate components.

The problem with monoliths is that they do not enforce isolation. It's up to the discipline of the developers to keep components isolated within an application, but we all know that eventually mistakes will be made. That's just human nature.

Microservices enforce this isolation, but the same could be achieved with separate OS processes or Docker containers.

***Everything is a trade-off***  
There is always a spectrum of decisions. The key is to find out what that spectrum is and what the trade-offs are.

**If someone tells you "this" is the only way to do things, they are lying to you.**

### New Adventures In Responsive Web Design
> Vitaly Friedman ([@vitalyf](https://twitter.com/vitalyf))

As the title suggests, this talk was about responsive web designs. I found this talk to be quite interesting, and even though I'm not currently focused on front-end development, I could see how some of the strategies Vitaly discussed would have had a positive impact on past projects I worked on. 

Staying on topic of "Old New Things", Vitaly started his talk by stating that style guides are nothing new. Back when teletext was still cool, we were already looking for ways to reuse and modularize design components.    

I found this talk to be quite fast paced and sometimes difficult to follow, but I will share what I managed pick up.

> *Think about the core essence of your web app, the necessary components, and then radiate outwards.*

When using a pattern library, try to avoid having a duplicate codebase for the library and the actual website. A potential solution for this is to build a component API on top of the library. (See [Lonely Planet's Rizzo](http://engineering.lonelyplanet.com/2014/05/18/a-maintainable-styleguide.html))

> *Speed and accessibility should be the main focus when building a web application. Scale/structure and style are also important, but come second.*  

Strategies that have a positive impact on performance include:

- **Service workers**  
A service worker is basically a js file in which you can declare a list of resources. These resources will then be cached locally.  
Using a service worker can even allow you to make parts of your website work without an internet connection.  
An issue that was not addressed however, was how changes to HTML, CSS or JS could be pushed to the client once they are cached.
- **Font loading**  
Properly understanding font loading can dramatically improve the performance of your website.
- **JAM stack**  
The main take-away was probably the [JAM stack](https://jamstack.org/), which Vitaly really seemed to underline.  
This stack promises to make your website much faster, and does this by pushing pre-baked HTML and JavaScript directly to a CDN. This avoids the need for a database (which is standard in most content management systems).  


Common pain points and bottlenecks that are present in almost every mid-size or large company:

- Subpar workflow and loose communication channels
- Tech-driven design decisions made by developers in silos
- Legacy code base, CMS and a slow workflow (a.k.a. watergile)
- Inconsistency across different views and environments
- Concerns about the right tooling and maintenance

The modern front-end challenges us to re-think the way we design and build experiences on the web:

- **Modular Approach** tackles the unpredictability of responsive behaviour
- **Modularity** can be achieved with SMCSS, BEM, Flexbox, CSS Grid, etc.
- **Performance and maintainability** shape the modern-day front-end
- **Designing components first** instead of thinking in pages i.e. [Atomic Design](http://bradfrost.com/blog/post/atomic-web-design/)  
Care must be taken when using Atomic Design however. It is generally useless for designers and can actually lead to disjointed experiences because it is open to interpretation.
 
### Taming servers infrastructure with Ansible
> Michal Ostruzska

I chose this talk because I'm currently on a project where we use Ansible to provision our development and test environments. I was hoping to compare our setup and way of working with that of the presenter and hopefully pick up some pointers. Sadly, this talk was more of a basic introduction, but I will summarize it nonetheless.
 
So for those of you who have no clue what Ansible is, it's basically a tool that allows you to provision a set machine and set up environments using infrastructure as code. It's a bit like Puppet, but easier to get into and completely based on configuration with yaml files.

Infrastructure as code
    - you can have it versioned
    - predictable -> same result evey time
    
Ansible vault decrypt/encrypt


Can we run tasks/plays in parallel?
Different strategies (free strategy)
Rolling deployments

Are there any restrictions on the type of architecture you can automate for? Let's say a system with distributed backend written in Java/C# and frontend in JS.
If you can deploy it using command line, you can deploy it using ansible.

Can you share some best practices / pitfalls that you encountered when using Ansible in your projects?
Grouping vairables reasonably, don't slice them into different files
Don't try to deploy to a real environment immediately; start with a vagrant machine and take a snapshot. You can then freely experiment, because when something goes wrong you can just reset the snapshot and try again.

### Lunch

### Metrics Driven Development
> Sam Elamin

Fully understanding everything in you application, what users are doing, how long it takes to repsond, how long services are running
=> Sounds like an ops job, but the engineers built it.

Benefits (became apparent in production)
- No more RDP
- Gives focus on what matters
- Freedom - experiment and see users using it by the minute

Types of metrics
- Business metrics - things that happen e.g. orders, payments
- Application metrics - response times (pinpoint bottlenecks)
- Infrastructure - cpu usage, memory, HD space

How to implement
Assign metrics to metric owners (start in your team)
For this sprint, what is the main goal (=metric)? e.g. we want to increase convergence
Then start collecting metrics

Don't measure everything (YAGNI)
Will lead to confusion about all the data you are collecting.
Fail fast. Try measuring different things and see if they are actually pushing the metric that you are interested in.

Start making decisions based on metrics.

Feature toggling

Alerts
Are basically acceptance tests that are constantly running in production.
Dips or changes in user behaviour is the system telling you that something might be wrong

Single source of truth => elastic + logstash + kibana

This gives high visibility into the platform
- how well a feature is running

You can share the graphs with business, helps them have conversations.

Prove that you can handle future higher loads *today*.

At what stage of development would you start measuring?
You start measuring in production, when you actually have the data

how you handle data structure changes then using feature toggle?
Feature toggle metrics just tell you whether a feature is toggled on or off, has nothing to do with data structures

Are you running anomaly detection and root-cause analysis on top of your time series/metrics/applications logs? How you tackle "alert fatigue"?
Something you learn as you go along, no surefire except experience. After anomaly, standup to find cause and fix

What dashboard do you prefer ?
Graphana, but depends on team

StatsD Graphite

### Around learning
> Alberto Brandolini

We need to feel like we did a good job. Just like when we were kids and gtting appreciation from our parents

The pink check (early waterfall)
autonomy -> totally depending on specs
mastery -> overdesigning architectures
purpse -> let's not screw up everything this time

" (late waterfall)
aut -> quessing and cutting corners
mastery -> cowboy coding
purpose -> let's get out of here

waterfall optimised for finger pointing (e.g. specs not complete, etc....)

what about agile?
-picture-

pink check ideal scrum
aut -> x-functional aut. team
mastery -> best engineering practuces
purpose -> satisfyong customers, shipping codeevery week

what is agile optimised for?
- responding to change?

secret desire is predictability

learning is the bottleneck - Dan North

we've been optimising the wrong thing => understanding the code and the system
learning isn't visible or deliverable so hard to optimize

Biggest risk is people going into production with stuff they don't understand
learning is an asset, but is not managed this way
focus on predictable delivery is postponing breakthroughs

experimenting basically paints a target on your back

companies are focusing on predictability -> some projects will need a different approach
we're developers
we're learners
we're hackers

learning is going to happen anyway, it's part of our job whether we want it or not
let's try a different perspective

antipattern -> product owner as domain expert
knowledge silos, nobody has all the knowledge

pink check
aut -> need to ask PO
mastery -> ...
prupose -> making the PO happy

solution -> event storming

single person knowing everything is a big risk, but a single person pretending to now everything is an even bigger risk
but who can tell the difference?

antipattern -> user stories as specification

template is a good shortcut for not thinking

pink check
aut -> need to ask po anyway
mastery -> ... (almost insulted)
purpose -> deliver something on friday

specifications are boring, learning is arch-enemy of boredom
so if specifications are boring   I won't be inclined to learn anything

whenever spec is too detailed (boring) -> let's let's add some new technology

antipattern -> domain expert as spoiler

write document so you don't waste time learning
but learning is actually needed

misconceptions about learning:
using experience to teach and avoid mistakes -> learning needs mistakes
doing something wrong and learning why it's wrong is crucial
experiment in a safe to fail context

being sold as an expert loses the opportunity to ask newbie questions

if you have a big question mark, make it explicit. there are probably 3-4 other people that have the same question and will thank you for it

antipattern-> dungeon master
-> blogpost

Black Box Thinking

pink check
aut -> as long as your chain (slave to the legacy)
mastery -> can't beat the dungeon master
purpose -> ...

=> I'll be learning somebody else's perversion

antipattern -> cadence
unecpected stimuli force us to think
iterations are repeating in a boring way

take a special day

the imediment list is long and the temptation for predictability is still there

antpattern -> reinventing the wheel
reinventing the wheel is learning (don't feel guilty about it)
stop pretending everything is a black box, look inside

accountants don't have a pet balance sheet but almost all programmers have a pet project

antipattern -> same office, same desk
antipattern -> exchangeable "resources"

working habits not designed for learning

developers in a vacuum
what is the purpose, who are we helping
without real prupose we'll find another one

learning is crucial
companies and working environments are not designed for learning
change your perspective and look for opportunities, smakk ideas can make a difference

### Decisions, Decisions
> Dan North

Every decision is a trade-off


development

#### build
automated
gain
- repeatabilty
- feedback
- time
lose
- flexibility
- knowledge of the build

"baking in your ignorance"

periodically lose the build and start again from cmd line

an automated build can hide ignorance
it's not better but different

#### testing
tests aren't good at telling the usual from the unusual
automated tests tell you stuff you already know,
manual tests can tell you stuff that you don't

#### TDD / TAD
Test first is different from test driven

putting developers and testers together is a powerful thing

Spike and Stabilize pattern
What is a spike?
Experiment in code designed to teach me something
You have to throw it away

Treat all code as a spike

TDD gives feedbqck from defects, Spike > PRD gives feedback from users
Based on PRD feedback you can delete code that isn't used, and test the code that is long lasting

invest in code based on evidence


architecture

monolith or components

don't distribute unless necessary

start with one thing, until it no longer fits in your head only then create the vision of how the architecture will work

serverless => mainframe

objects or functions
functional is far simpler than OO, hard to think that simple

sync or async
building a sync api on an async system is simpler that the other way around

threads or event loops
when contemplating dist systems or concurrency you need to understand actors and CSP

csp less flexible but easier to reason about than actor model

Short software half-life pattern
How long do you have to walk away for before half the code has changed

All code is cost & a liability, change code when you can

Every month half the code at google changes

You need small separate components
Each one does one thing
hard shell, soft centre -> clearly defined api, but flexible implementation
the message (event) is the api -> they define the behaviour of the system

Provides identifiable boundaries for experimentation


Evolvable architecture

DRY or decoupled
trade-off for DRY is coupling and simplicity 

evolution is anything bt DRY -> each generation is copy paste (DNA doesn't refactor)

Ginger Cake pattern
it's ok to copy paste if you are intimate with the code you're copying in the first place


Deployment

automated or manual
If you don't know what the path to production looks like, you have no rights automating it
automate something when it is boring
-> done it lots of times = you understand it
-> always the same
otherwise not worth automating, opportunity cost (what's all the stuff you could have done while automating it)

don't spend the first weeks on a project automating the entire pipeline, always be shipping something

vertical or horizontal scaling

managed or in-house

virtual or physical

Dancing Skeleton pattern

Get something - anything! - in production (= full stack, with an interface)
tells you how it acts and behaves in production,
Fire, aim, ready! -> use feedback from prd to make changes

Theory is like practice in theory

### Discussion panel









